{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLM-R-NER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVmLbSWy2E2L6r3Rhc07oj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrichajalota/software-project/blob/main/XLM_R_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1VAMZP3dcEl"
      },
      "source": [
        "!export PARAM_SET=base # change to large to use the large architecture\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "288Krts1dmAG",
        "outputId": "dfbd98db-4eee-47cc-f3c5-6d9ce714aade"
      },
      "source": [
        "!git clone https://github.com/mohammadKhalifa/xlm-roberta-ner.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xlm-roberta-ner'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (312/312), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 312 (delta 165), reused 245 (delta 118), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (312/312), 2.89 MiB | 7.27 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwwy5wtHduAo",
        "outputId": "de67c56b-aaf8-4f9f-81f8-283215da097e"
      },
      "source": [
        "%cd xlm-roberta-ner/\n",
        "!mkdir pretrained_models "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlm-roberta-ner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knZd2IA6dyHi",
        "outputId": "2ea70852-a70a-4f38-84a2-735de01a1f00"
      },
      "source": [
        "!wget -P pretrained_models https://dl.fbaipublicfiles.com/fairseq/models/xlmr.base.tar.gz\n",
        "!tar xzvf pretrained_models/xlmr.base.tar.gz  --directory pretrained_models/\n",
        "!rm -r pretrained_models/xlmr.base.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-09 08:30:49--  https://dl.fbaipublicfiles.com/fairseq/models/xlmr.base.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 512274718 (489M) [application/gzip]\n",
            "Saving to: ‘pretrained_models/xlmr.base.tar.gz’\n",
            "\n",
            "xlmr.base.tar.gz    100%[===================>] 488.54M  25.6MB/s    in 13s     \n",
            "\n",
            "2021-08-09 08:31:03 (36.3 MB/s) - ‘pretrained_models/xlmr.base.tar.gz’ saved [512274718/512274718]\n",
            "\n",
            "xlmr.base/\n",
            "xlmr.base/dict.txt\n",
            "xlmr.base/sentencepiece.bpe.model\n",
            "xlmr.base/model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeM2laO-C8FZ",
        "outputId": "9887ebe0-de0d-4600-d808-e2c879500f74"
      },
      "source": [
        "!pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 17.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.16-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 54.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.22.0,>=1.21.16\n",
            "  Downloading botocore-1.21.16-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 61.2 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.16->boto3->pytorch_transformers) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.16->boto3->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.16 botocore-1.21.16 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zjtf40wFd1xF",
        "outputId": "6f3f0131-d12e-4591-f52e-3efe7f6650f7"
      },
      "source": [
        "!pip install seqeval fairseq torch pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting fairseq\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.23)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.41.1)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.18.16)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.96)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.45)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.16 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.21.16)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.16->boto3->pytorch_transformers) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.16->boto3->pytorch_transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.16->boto3->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Building wheels for collected packages: seqeval, antlr4-python3-runtime\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=f5d8e8604c7cfbb6a617eb855a6b5a9a837b24dc8d751f13f3921b393e5b060f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=b3f303ae8850cdfc400105e5584b3e5f61da2f3dfb6682cfad187b7e7115a2f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built seqeval antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, dataclasses, seqeval, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.0 omegaconf-2.1.0 portalocker-2.0.0 sacrebleu-1.5.1 seqeval-1.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PM1dMvoJ6b6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjqqJadLeLK2",
        "outputId": "d47ecde7-5239-41d7-d693-2b40afed2287"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iosn9CbqejIF",
        "outputId": "642af9a0-d442-46e0-b7ed-a14904d4677f"
      },
      "source": [
        "%cd xlm-roberta-ner/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlm-roberta-ner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYpi4Z9qeucW",
        "outputId": "5b42b30b-2e8c-4a5c-d395-897efe78b07f"
      },
      "source": [
        "!python main.py --data_dir=../hi/ --task_name=ner --output_dir=model_out/ --max_seq_length=32 --num_train_epochs=10 --warmup_proportion=0.0 --learning_rate 6e-5 --gradient_accumulation_steps 4 --dropout 0.2 --train_batch_size 32 --pretrained_path pretrained_models/xlmr.base/ --do_train --freeze_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/09/2021 08:58:54 - INFO - fairseq.file_utils -   loading archive file pretrained_models/xlmr.base/\n",
            "08/09/2021 08:58:55 - INFO - fairseq.tasks.multilingual_masked_lm -   dictionary: 250001 types\n",
            "08/09/2021 08:59:06 - INFO - __main__ -   Freezing XLM-R model...\n",
            "08/09/2021 08:59:06 - INFO - root -   *** Example ***\n",
            "08/09/2021 08:59:06 - INFO - root -   guid: train-0\n",
            "08/09/2021 08:59:06 - INFO - root -   tokens: 0 114072 9337 1142 5564 108761 1302 629 151677 287 35350 996 2653 8188 14205 1302 421 91893 1187 641 78614 30716 125 21191 64781 19131 14910 287 1812 31630 55804 2\n",
            "08/09/2021 08:59:06 - INFO - root -   input_ids: 0 114072 9337 1142 5564 108761 1302 629 151677 287 35350 996 2653 8188 14205 1302 421 91893 1187 641 78614 30716 125 21191 64781 19131 14910 287 1812 31630 55804 2\n",
            "08/09/2021 08:59:06 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:06 - INFO - root -   label: ['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'] (id = 0 1 0 1 1 1 0 1 6 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 2 0 0)\n",
            "08/09/2021 08:59:06 - INFO - root -   label_mask: 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            "08/09/2021 08:59:06 - INFO - root -   valid mask: 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            "08/09/2021 08:59:06 - INFO - root -   *** Example ***\n",
            "08/09/2021 08:59:06 - INFO - root -   guid: train-1\n",
            "08/09/2021 08:59:06 - INFO - root -   tokens: 0 287 17912 2284 238692 20 20546 45951 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:06 - INFO - root -   input_ids: 0 287 17912 2284 238692 20 20546 45951 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:06 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:06 - INFO - root -   label: ['B-PER', 'I-PER', 'O', 'O'] (id = 0 2 0 0 3 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 08:59:06 - INFO - root -   label_mask: 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:06 - INFO - root -   valid mask: 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - __main__ -   ***** Running training *****\n",
            "08/09/2021 08:59:07 - INFO - __main__ -     Num examples = 5019\n",
            "08/09/2021 08:59:07 - INFO - __main__ -     Batch size = 8\n",
            "08/09/2021 08:59:07 - INFO - __main__ -     Num steps = 1560\n",
            "08/09/2021 08:59:07 - INFO - root -   *** Example ***\n",
            "08/09/2021 08:59:07 - INFO - root -   guid: valid-0\n",
            "08/09/2021 08:59:07 - INFO - root -   tokens: 0 5602 1964 34318 6960 838 91462 127285 117829 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:07 - INFO - root -   input_ids: 0 5602 1964 34318 6960 838 91462 127285 117829 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:07 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - root -   label: ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG'] (id = 0 4 0 0 5 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 08:59:07 - INFO - root -   label_mask: 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - root -   valid mask: 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - root -   *** Example ***\n",
            "08/09/2021 08:59:07 - INFO - root -   guid: valid-1\n",
            "08/09/2021 08:59:07 - INFO - root -   tokens: 0 95366 3346 4377 68340 209062 1302 89672 998 15 384 5014 7510 75635 12651 1388 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:07 - INFO - root -   input_ids: 0 95366 3346 4377 68340 209062 1302 89672 998 15 384 5014 7510 75635 12651 1388 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 08:59:07 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - root -   label: ['B-LOC', 'O', 'O', 'O'] (id = 0 6 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 08:59:07 - INFO - root -   label_mask: 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 08:59:07 - INFO - root -   valid mask: 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "main.py:147: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for _ in tqdm(range(args.num_train_epochs), desc=\"Epoch\"):\n",
            "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…\n",
            "main.py:151: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  tbar = tqdm(train_dataloader, desc=\"Iteration\")\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "08/09/2021 08:59:19 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "08/09/2021 08:59:21 - INFO - __main__ -   \n",
            "Found better f1=0.0101 on validation set. Saving model\n",
            "\n",
            "08/09/2021 08:59:21 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.0000    0.0000    0.0000       422\n",
            "         ORG     0.0503    0.0217    0.0303       369\n",
            "         PER     0.0000    0.0000    0.0000       429\n",
            "\n",
            "   micro avg     0.0485    0.0066    0.0116      1220\n",
            "   macro avg     0.0168    0.0072    0.0101      1220\n",
            "weighted avg     0.0152    0.0066    0.0092      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 08:59:36 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 08:59:38 - INFO - __main__ -   \n",
            "Found better f1=0.1473 on validation set. Saving model\n",
            "\n",
            "08/09/2021 08:59:38 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     1.0000    0.0142    0.0280       422\n",
            "         ORG     0.1701    0.1816    0.1756       369\n",
            "         PER     0.2752    0.2098    0.2381       429\n",
            "\n",
            "   micro avg     0.2242    0.1336    0.1674      1220\n",
            "   macro avg     0.4818    0.1352    0.1473      1220\n",
            "weighted avg     0.4941    0.1336    0.1465      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 08:59:55 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 08:59:57 - INFO - __main__ -   \n",
            "Found better f1=0.2633 on validation set. Saving model\n",
            "\n",
            "08/09/2021 08:59:57 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.4348    0.1185    0.1862       422\n",
            "         ORG     0.1853    0.2331    0.2065       369\n",
            "         PER     0.3569    0.4476    0.3971       429\n",
            "\n",
            "   micro avg     0.2936    0.2689    0.2807      1220\n",
            "   macro avg     0.3257    0.2664    0.2633      1220\n",
            "weighted avg     0.3319    0.2689    0.2665      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:00:25 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:00:27 - INFO - __main__ -   \n",
            "Found better f1=0.3161 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:00:27 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3879    0.1967    0.2610       422\n",
            "         ORG     0.1911    0.2791    0.2269       369\n",
            "         PER     0.4046    0.5338    0.4603       429\n",
            "\n",
            "   micro avg     0.3146    0.3402    0.3269      1220\n",
            "   macro avg     0.3278    0.3365    0.3161      1220\n",
            "weighted avg     0.3342    0.3402    0.3208      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:00:54 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:00:56 - INFO - __main__ -   \n",
            "Found better f1=0.3616 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:00:56 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3994    0.3009    0.3432       422\n",
            "         ORG     0.1978    0.2900    0.2352       369\n",
            "         PER     0.4399    0.5967    0.5064       429\n",
            "\n",
            "   micro avg     0.3400    0.4016    0.3683      1220\n",
            "   macro avg     0.3457    0.3959    0.3616      1220\n",
            "weighted avg     0.3526    0.4016    0.3679      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:01:23 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:01:25 - INFO - __main__ -   \n",
            "Found better f1=0.3635 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:01:25 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3723    0.3318    0.3509       422\n",
            "         ORG     0.1810    0.2276    0.2017       369\n",
            "         PER     0.4530    0.6620    0.5379       429\n",
            "\n",
            "   micro avg     0.3463    0.4164    0.3781      1220\n",
            "   macro avg     0.3354    0.4071    0.3635      1220\n",
            "weighted avg     0.3428    0.4164    0.3715      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:01:47 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:01:49 - INFO - __main__ -   \n",
            "Found better f1=0.3712 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:01:49 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3808    0.3294    0.3532       422\n",
            "         ORG     0.1880    0.2466    0.2134       369\n",
            "         PER     0.4615    0.6713    0.5470       429\n",
            "\n",
            "   micro avg     0.3517    0.4246    0.3847      1220\n",
            "   macro avg     0.3435    0.4158    0.3712      1220\n",
            "weighted avg     0.3509    0.4246    0.3791      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:02:18 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:02:20 - INFO - __main__ -   \n",
            "Found better f1=0.3841 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:02:20 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3846    0.3555    0.3695       422\n",
            "         ORG     0.1936    0.2629    0.2230       369\n",
            "         PER     0.4699    0.6923    0.5598       429\n",
            "\n",
            "   micro avg     0.3572    0.4459    0.3966      1220\n",
            "   macro avg     0.3494    0.4369    0.3841      1220\n",
            "weighted avg     0.3568    0.4459    0.3921      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:02:44 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:02:46 - INFO - __main__ -   \n",
            "Found better f1=0.3939 on validation set. Saving model\n",
            "\n",
            "08/09/2021 09:02:46 - INFO - __main__ -                 precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.3979    0.3649    0.3807       422\n",
            "         ORG     0.2008    0.2818    0.2345       369\n",
            "         PER     0.4727    0.7063    0.5664       429\n",
            "\n",
            "   micro avg     0.3629    0.4598    0.4056      1220\n",
            "   macro avg     0.3571    0.4510    0.3939      1220\n",
            "weighted avg     0.3646    0.4598    0.4018      1220\n",
            "\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=628.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "08/09/2021 09:03:12 - INFO - __main__ -   \n",
            "Testing on validation set...\n",
            "08/09/2021 09:03:14 - INFO - __main__ -   \n",
            "No better F1 score: 0.3932196235286347\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQXgjCZAUthY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615d0c13-aadd-45c5-a97c-6ac40ecb084d"
      },
      "source": [
        "!python main.py --data_dir=../hi/ --task_name=ner --output_dir=model_out/ --max_seq_length=32 --num_train_epochs=5 --warmup_proportion=0.0 --learning_rate 6e-5 --gradient_accumulation_steps 4 --dropout 0.2 --train_batch_size 32 --pretrained_path pretrained_models/xlmr.base/ --do_eval --eval_on test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/09/2021 09:04:56 - INFO - fairseq.file_utils -   loading archive file pretrained_models/xlmr.base/\n",
            "08/09/2021 09:04:57 - INFO - fairseq.tasks.multilingual_masked_lm -   dictionary: 250001 types\n",
            "08/09/2021 09:05:11 - INFO - __main__ -   Loaded saved model\n",
            "08/09/2021 09:05:11 - INFO - root -   *** Example ***\n",
            "08/09/2021 09:05:11 - INFO - root -   guid: test-0\n",
            "08/09/2021 09:05:11 - INFO - root -   tokens: 0 1618 142720 87042 128432 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:05:11 - INFO - root -   input_ids: 0 1618 142720 87042 128432 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:05:11 - INFO - root -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - root -   label: ['B-LOC', 'I-LOC', 'I-LOC'] (id = 0 6 0 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 09:05:11 - INFO - root -   label_mask: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - root -   valid mask: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - root -   *** Example ***\n",
            "08/09/2021 09:05:11 - INFO - root -   guid: test-1\n",
            "08/09/2021 09:05:11 - INFO - root -   tokens: 0 182906 43451 2815 421 2220 171103 4846 871 4623 78346 998 182906 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:05:11 - INFO - root -   input_ids: 0 182906 43451 2815 421 2220 171103 4846 871 4623 78346 998 182906 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:05:11 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - root -   label: ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O'] (id = 0 1 6 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 09:05:11 - INFO - root -   label_mask: 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - root -   valid mask: 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:05:11 - INFO - __main__ -   ***** Running evaluation *****\n",
            "08/09/2021 09:05:11 - INFO - __main__ -     Num examples = 1002\n",
            "08/09/2021 09:05:11 - INFO - __main__ -     Batch size = 32\n",
            "08/09/2021 09:05:13 - INFO - __main__ -   \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.4252    0.3932    0.4086       412\n",
            "         ORG     0.2515    0.3380    0.2884       361\n",
            "         PER     0.4953    0.7060    0.5822       449\n",
            "\n",
            "   micro avg     0.3991    0.4918    0.4406      1222\n",
            "   macro avg     0.3907    0.4791    0.4264      1222\n",
            "weighted avg     0.3997    0.4918    0.4369      1222\n",
            "\n",
            "08/09/2021 09:05:13 - INFO - __main__ -   ***** Writing results to file *****\n",
            "08/09/2021 09:05:13 - INFO - __main__ -   Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-fL_8l2fzji",
        "outputId": "f2e3df4b-7340-451f-8c42-768feaeb0ce8"
      },
      "source": [
        "!python main.py --data_dir=../hi/ --task_name=ner --output_dir=model_out/ --max_seq_length=32 --num_train_epochs=5 --warmup_proportion=0.0 --learning_rate 6e-5 --gradient_accumulation_steps 4 --dropout 0.2 --train_batch_size 32 --pretrained_path pretrained_models/xlmr.base/ --do_eval --eval_on test --freeze_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/09/2021 09:06:31 - INFO - fairseq.file_utils -   loading archive file pretrained_models/xlmr.base/\n",
            "08/09/2021 09:06:31 - INFO - fairseq.tasks.multilingual_masked_lm -   dictionary: 250001 types\n",
            "08/09/2021 09:06:42 - INFO - __main__ -   Freezing XLM-R model...\n",
            "08/09/2021 09:06:43 - INFO - __main__ -   Loaded saved model\n",
            "08/09/2021 09:06:43 - INFO - root -   *** Example ***\n",
            "08/09/2021 09:06:43 - INFO - root -   guid: test-0\n",
            "08/09/2021 09:06:43 - INFO - root -   tokens: 0 1618 142720 87042 128432 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:06:43 - INFO - root -   input_ids: 0 1618 142720 87042 128432 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:06:43 - INFO - root -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - root -   label: ['B-LOC', 'I-LOC', 'I-LOC'] (id = 0 6 0 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 09:06:43 - INFO - root -   label_mask: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - root -   valid mask: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - root -   *** Example ***\n",
            "08/09/2021 09:06:43 - INFO - root -   guid: test-1\n",
            "08/09/2021 09:06:43 - INFO - root -   tokens: 0 182906 43451 2815 421 2220 171103 4846 871 4623 78346 998 182906 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:06:43 - INFO - root -   input_ids: 0 182906 43451 2815 421 2220 171103 4846 871 4623 78346 998 182906 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/09/2021 09:06:43 - INFO - root -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - root -   label: ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O'] (id = 0 1 6 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)\n",
            "08/09/2021 09:06:43 - INFO - root -   label_mask: 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - root -   valid mask: 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/09/2021 09:06:43 - INFO - __main__ -   ***** Running evaluation *****\n",
            "08/09/2021 09:06:43 - INFO - __main__ -     Num examples = 1002\n",
            "08/09/2021 09:06:43 - INFO - __main__ -     Batch size = 32\n",
            "08/09/2021 09:06:45 - INFO - __main__ -   \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.4252    0.3932    0.4086       412\n",
            "         ORG     0.2515    0.3380    0.2884       361\n",
            "         PER     0.4953    0.7060    0.5822       449\n",
            "\n",
            "   micro avg     0.3991    0.4918    0.4406      1222\n",
            "   macro avg     0.3907    0.4791    0.4264      1222\n",
            "weighted avg     0.3997    0.4918    0.4369      1222\n",
            "\n",
            "08/09/2021 09:06:45 - INFO - __main__ -   ***** Writing results to file *****\n",
            "08/09/2021 09:06:45 - INFO - __main__ -   Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0rteX5ULg-X"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6fXQ0NwLvn3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfOg5T9QL-Ra"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaPHI3hfMM66"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi4tbVA7MbkY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIox9U9MqN3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOS8iNvGM43a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ8OGFvHNHg5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn2OQuctNWKZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pej-0czhNkz5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwVnDUhNzdZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmTe3yuTOCG5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5ACuz2OQwZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZElmgIc2OfZ5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C7_t3RrOuDZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ua7rnMO8s5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKggF4d5PLWZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umwa2ySdPZ_5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUxzW8YAPopZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdsOvZ4CP3S5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QgiIk9QQF8Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udby75BvQUl5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-CgXp1aQjPd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKDhhYjqQx45"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GekGLKaeRAid"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdcf_VIqRPL5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYZLTje4Rd1Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gwPMiAHRse5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlwGJ-VwR7IY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgEnlQnSSJx5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9cX6jd0SYbZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMD3L6pJSnE6"
      },
      "source": [
        ""
      ]
    }
  ]
}